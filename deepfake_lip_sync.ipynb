{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deepfake_lip_sync.ipynb","provenance":[{"file_id":"1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8","timestamp":1621820748951},{"file_id":"1NLUwupCBsB1HrpEmOIHeMgU63sus2LxP","timestamp":1597735440478}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AYBXSU0U8s8z"},"source":["## Rithish Kumar\n","\n","###Credits to Wav2Lip pretrained model"]},{"cell_type":"code","metadata":{"id":"XIVB0Xn1g6ih","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621842729362,"user_tz":-330,"elapsed":469,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"13bb3386-1069-49ce-8778-8cac0d81fefc"},"source":["!nvcc --version"],"execution_count":3,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qciH4PsUazL_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621853509422,"user_tz":-330,"elapsed":7060,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"86216fa6-537f-44b9-d5ba-6d5ec652e586"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yJ5taGmPcWV-"},"source":["# Getting Pretrained Wav2Lip program from git.\n","which can be used for academic and research purposes."]},{"cell_type":"code","metadata":{"id":"P3LihClHbUd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621853511848,"user_tz":-330,"elapsed":798,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"c6665ee4-6c87-4eef-8459-f74dd382e1bc"},"source":["!git clone https://github.com/Rudrabha/Wav2Lip.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'Wav2Lip'...\n","remote: Enumerating objects: 338, done.\u001b[K\n","remote: Total 338 (delta 0), reused 0 (delta 0), pack-reused 338\u001b[K\n","Receiving objects: 100% (338/338), 511.49 KiB | 12.18 MiB/s, done.\n","Resolving deltas: 100% (184/184), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMC7BIdCTdPQ","executionInfo":{"status":"ok","timestamp":1621853514090,"user_tz":-330,"elapsed":703,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"066df8eb-260c-43d2-864f-a3bd5691115c"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data  Wav2Lip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YjzMPy_Sb0AI","executionInfo":{"status":"ok","timestamp":1621853522275,"user_tz":-330,"elapsed":6898,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}}},"source":["!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-1O9NyQGMDR","executionInfo":{"status":"ok","timestamp":1621855144984,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}}},"source":["!cp -ri \"/content/gdrive/MyDrive/Wav2lip/haarcascade_frontalface_alt2.xml\" /content/"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWTaOS3ncFt6"},"source":["# Get the pre-requisites"]},{"cell_type":"code","metadata":{"id":"Ooh28vw-Uvd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621853554828,"user_tz":-330,"elapsed":32576,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"725f335a-0683-4be5-b9fa-cc3b49f12650"},"source":["!pip uninstall tensorflow tensorflow-gpu"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.4.1\n","\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"49dCYlLdcK2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621853728068,"user_tz":-330,"elapsed":173249,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"62557e47-93b0-4aef-b8c2-be578811baba"},"source":["!cd Wav2Lip && pip install -r requirements.txt"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting librosa==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/6e/0eb0de1c9c4e02df0b40e56f258eb79bd957be79b918511a184268e01720/librosa-0.7.0.tar.gz (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 7.2MB/s \n","\u001b[?25hCollecting numpy==1.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/eb/4ecf6b13897391cb07a4231e9d9c671b55dfbbf6f4a514a1a0c594f2d8d9/numpy-1.17.1-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n","\u001b[K     |████████████████████████████████| 20.3MB 1.2MB/s \n","\u001b[?25hCollecting opencv-contrib-python>=4.2.0.34\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/77/347867aff4a9a5b56ea587a50762fb0ba40b27bb4e8f8f27c25ba57ed807/opencv_contrib_python-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (57.4MB)\n","\u001b[K     |████████████████████████████████| 57.4MB 49kB/s \n","\u001b[?25hCollecting opencv-python==4.1.0.25\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/52/61b9619a7a95a8d809515f68f1441224a07ce1873fd3af5e662851014a55/opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n","\u001b[K     |████████████████████████████████| 26.6MB 116kB/s \n","\u001b[?25hCollecting torch==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/23/a4b5c189dd624411ec84613b717594a00480282b949e3448d189c4aa4e47/torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9MB)\n","\u001b[K     |████████████████████████████████| 676.9MB 26kB/s \n","\u001b[?25hCollecting torchvision==0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/9b/208f48d5a5013bdb0c27a84a02df4fcf5fd24ab5902667c11e554a12b681/torchvision-0.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 22.3MB/s \n","\u001b[?25hCollecting tqdm==4.45.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n","\u001b[?25hCollecting numba==0.48\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/dc/5ce4a94d98e8a31cab21b150e23ca2f09a7dd354c06a69f71801ecd890db/numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5MB)\n","\u001b[K     |████████████████████████████████| 3.6MB 28.7MB/s \n","\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (2.1.9)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (4.4.2)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.2.2)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.10.3.post1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.3.0->-r requirements.txt (line 6)) (7.1.2)\n","Collecting llvmlite<0.32.0,>=0.31.0dev0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/10/d02c0ac683fc47ecda3426249509cf771d748b6a2c0e9d5ebbee76a7b80a/llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)\n","\u001b[K     |████████████████████████████████| 20.2MB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48->-r requirements.txt (line 8)) (56.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (2.20)\n","Building wheels for collected packages: librosa\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.7.0-cp37-none-any.whl size=1598345 sha256=938e2a437fa2fbb12128a95b7ec5284b042dd195131a36cacb4013d438286e8b\n","  Stored in directory: /root/.cache/pip/wheels/49/1d/38/c8ad12fcad67569d8e730c3275be5e581bd589558484a0f881\n","Successfully built librosa\n","\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, llvmlite, numba, librosa, opencv-contrib-python, opencv-python, torch, torchvision, tqdm\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","  Found existing installation: librosa 0.8.0\n","    Uninstalling librosa-0.8.0:\n","      Successfully uninstalled librosa-0.8.0\n","  Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","  Found existing installation: torchvision 0.9.1+cu101\n","    Uninstalling torchvision-0.9.1+cu101:\n","      Successfully uninstalled torchvision-0.9.1+cu101\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed librosa-0.7.0 llvmlite-0.31.0 numba-0.48.0 numpy-1.17.1 opencv-contrib-python-4.5.2.52 opencv-python-4.1.0.25 torch-1.1.0 torchvision-0.3.0 tqdm-4.45.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ey_bN4M6X_95","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621853745822,"user_tz":-330,"elapsed":6623,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"fca247d4-9e90-407d-8277-77440150d9b8"},"source":["!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["--2021-05-24 10:55:39--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n","Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n","Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 89843225 (86M) [application/octet-stream]\n","Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n","\n","Wav2Lip/face_detect 100%[===================>]  85.68M  18.0MB/s    in 5.6s    \n","\n","2021-05-24 10:55:45 (15.4 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlgBMoO14d4E","executionInfo":{"status":"ok","timestamp":1621853745825,"user_tz":-330,"elapsed":24,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"2d547c72-f228-4b07-e239-7d6aa2a2c1e0"},"source":["%cd /content"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qUGuqlx4N_-0"},"source":["#### Function to upload our file to colab."]},{"cell_type":"code","metadata":{"id":"yAmXOaRjVLSj","executionInfo":{"status":"ok","timestamp":1621853747631,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}}},"source":["def upload(savename):\n","  from google.colab import files\n","  uploaded = files.upload() \n","  for name, data in uploaded.items():\n","    with open(savename, 'wb') as f:\n","      f.write(data)\n","      print ('saved file', name)\n","  return name\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qdIQfY2Kswcb"},"source":["# Now Lets do some deep fakes\n","\n","First we are getting ip from user and get to our local storage.\n"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":109},"id":"GY9ZGD46UFW3","executionInfo":{"status":"ok","timestamp":1621853898726,"user_tz":-330,"elapsed":147982,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"1942d3da-ab57-4e0f-df6d-966da8fd87d0"},"source":["upload('input_raw.mp4')"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-7aa1ce41-c566-4f7a-8bff-97d00f3ab48f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-7aa1ce41-c566-4f7a-8bff-97d00f3ab48f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving videoplayback (3).mp4 to videoplayback (3).mp4\n","saved file videoplayback (3).mp4\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'videoplayback (3).mp4'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":109},"id":"869zWKnwYflT","executionInfo":{"status":"ok","timestamp":1621854027662,"user_tz":-330,"elapsed":121760,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"5e01defe-cc08-4520-c1cf-e74995b0b9dc"},"source":["upload('input_audio.mp4')"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-4c0d3b50-00a7-4eb9-b44f-38448ed19049\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-4c0d3b50-00a7-4eb9-b44f-38448ed19049\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving videoplayback (4).mp4 to videoplayback (4).mp4\n","saved file videoplayback (4).mp4\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'videoplayback (4).mp4'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"JSejZZK-OZCs"},"source":["## From the main footage we are getting frames with faces."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZY9XcvpvE3ri","executionInfo":{"status":"ok","timestamp":1621856558913,"user_tz":-330,"elapsed":154391,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"1c2317db-474a-4c04-b37f-3613fc3cc6ec"},"source":["import cv2\n","face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_alt2.xml')\n","  \n","\n","# Create an object to read\n","# from camera\n","video = cv2.VideoCapture('/content/input_raw.mp4')\n","\n","# We need to check if camera\n","# is opened previously or not\n","if (video.isOpened() == False):\n","\tprint(\"Error reading video file\")\n","\n","# We need to set resolutions.\n","# so, convert them from float to integer.\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","\n","size = (frame_width, frame_height)\n","\n","# Below VideoWriter object will create\n","# a frame of above defined The output\n","# is stored in 'filename.avi' file.\n","result = cv2.VideoWriter('input.mp4',\n","\t\t\t\t\t\tcv2.VideoWriter_fourcc(*'MJPG'),\n","\t\t\t\t\t\t10, size)\n","\t\n","while(True):\n","  ret, frame = video.read()\n","\n","  if ret == True:\n","    p=0\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","# Detects faces of different sizes in the input image\n","    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n","    c=0\n","    for face in faces:\n","      c+=1\n","# Write the frame into the\n","# file 'filename.avi'\n","    if c!=0:\n","      result.write(frame)\n","\n","\n","  else:\n","    break\n","\n","# When everything done, release\n","# the video capture and video\n","# write objects\n","video.release()\n","result.release()\n","\t\n","\n","\n","print(\"The video was successfully saved\")\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["The video was successfully saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Atxxnvu9a8kV","executionInfo":{"status":"ok","timestamp":1621854051157,"user_tz":-330,"elapsed":445,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"687c7c2e-c116-495d-bfd8-5032513b8d2a"},"source":["%cd /content/Wav2Lip/"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/Wav2Lip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tMtV4_94OsBI"},"source":["### Setting model and doing lip_sync"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BM3gmw7GAqZC","executionInfo":{"status":"ok","timestamp":1621856831833,"user_tz":-330,"elapsed":86191,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"ac941e5f-69d6-4e73-f9ea-207688270849"},"source":["from os import listdir, path\n","import numpy as np\n","import scipy, cv2, os, sys, argparse, audio\n","import json, subprocess, random, string\n","from tqdm import tqdm\n","from glob import glob\n","import torch, face_detection\n","from models import Wav2Lip\n","import platform\n","checkpoint_path=\"checkpoints/wav2lip_gan.pth\"\n","\n","face='/content/input.mp4'\n","audiof='/content/input_audio.mp4'\n","outfile='results/result_voice.mp4'\n","\n","static=False\n","fps=25\n","pads=[0,10,0,0]\n","face_det_batch_size =16\n","wav2lip_batch_size=128\n","resize_factor=1\n","crop=[0, -1, 0, -1]\n","box=[-1, -1, -1, -1]\n","rotate=False\n","nosmooth=False\n","\n","img_size = 96\n","\n","if os.path.isfile(face) and face.split('.')[1] in ['jpg', 'png', 'jpeg']:\n","\tstatic = True\n","\n","def get_smoothened_boxes(boxes, T):\n","\tfor i in range(len(boxes)):\n","\t\tif i + T > len(boxes):\n","\t\t\twindow = boxes[len(boxes) - T:]\n","\t\telse:\n","\t\t\twindow = boxes[i : i + T]\n","\t\tboxes[i] = np.mean(window, axis=0)\n","\treturn boxes\n","\n","def face_detect(images):\n","\tdetector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, \n","\t\t\t\t\t\t\t\t\t\t\tflip_input=False, device=device)\n","\n","\tbatch_size =face_det_batch_size\n","\t\n","\twhile 1:\n","\t\tpredictions = []\n","\t\ttry:\n","\t\t\tfor i in tqdm(range(0, len(images), batch_size)):\n","\t\t\t\tpredictions.extend(detector.get_detections_for_batch(np.array(images[i:i + batch_size])))\n","\t\texcept RuntimeError:\n","\t\t\tif batch_size == 1: \n","\t\t\t\traise RuntimeError('Image too big to run face detection on GPU. Please use the --resize_factor argument')\n","\t\t\tbatch_size //= 2\n","\t\t\tprint('Recovering from OOM error; New batch size: {}'.format(batch_size))\n","\t\t\tcontinue\n","\t\tbreak\n","\n","\tresults = []\n","\tpady1, pady2, padx1, padx2 = pads\n","\tfor rect, image in zip(predictions, images):\n","\t\tif rect is None:\n","\t\t\tcv2.imwrite('temp/faulty_frame.jpg', image) # check this frame where the face was not detected.\n","\t\t\traise ValueError('Face not detected! Ensure the video contains a face in all the frames.')\n","\n","\t\ty1 = max(0, rect[1] - pady1)\n","\t\ty2 = min(image.shape[0], rect[3] + pady2)\n","\t\tx1 = max(0, rect[0] - padx1)\n","\t\tx2 = min(image.shape[1], rect[2] + padx2)\n","\t\t\n","\t\tresults.append([x1, y1, x2, y2])\n","\n","\tboxes = np.array(results)\n","\tif not nosmooth: boxes = get_smoothened_boxes(boxes, T=5)\n","\tresults = [[image[y1: y2, x1:x2], (y1, y2, x1, x2)] for image, (x1, y1, x2, y2) in zip(images, boxes)]\n","\n","\tdel detector\n","\treturn results \n","\n","def datagen(frames, mels):\n","\timg_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n","\n","\tif box[0] == -1:\n","\t\tif not static:\n","\t\t\tface_det_results = face_detect(frames) # BGR2RGB for CNN face detection\n","\t\telse:\n","\t\t\tface_det_results = face_detect([frames[0]])\n","\telse:\n","\t\tprint('Using the specified bounding box instead of face detection...')\n","\t\ty1, y2, x1, x2 = box\n","\t\tface_det_results = [[f[y1: y2, x1:x2], (y1, y2, x1, x2)] for f in frames]\n","\n","\tfor i, m in enumerate(mels):\n","\t\tidx = 0 if static else i%len(frames)\n","\t\tframe_to_save = frames[idx].copy()\n","\t\tface, coords = face_det_results[idx].copy()\n","\n","\t\tface = cv2.resize(face, (img_size,img_size))\n","\t\t\t\n","\t\timg_batch.append(face)\n","\t\tmel_batch.append(m)\n","\t\tframe_batch.append(frame_to_save)\n","\t\tcoords_batch.append(coords)\n","\n","\t\tif len(img_batch) >= wav2lip_batch_size:\n","\t\t\timg_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n","\n","\t\t\timg_masked = img_batch.copy()\n","\t\t\timg_masked[:,img_size//2:] = 0\n","\n","\t\t\timg_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n","\t\t\tmel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n","\n","\t\t\tyield img_batch, mel_batch, frame_batch, coords_batch\n","\t\t\timg_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n","\n","\tif len(img_batch) > 0:\n","\t\timg_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n","\n","\t\timg_masked = img_batch.copy()\n","\t\timg_masked[:, img_size//2:] = 0\n","\n","\t\timg_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n","\t\tmel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n","\n","\t\tyield img_batch, mel_batch, frame_batch, coords_batch\n","\n","mel_step_size = 16\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using {} for inference.'.format(device))\n","\n","def _load(checkpoint_path):\n","\tif device == 'cuda':\n","\t\tcheckpoint = torch.load(checkpoint_path)\n","\telse:\n","\t\tcheckpoint = torch.load(checkpoint_path,\n","\t\t\t\t\t\t\t\tmap_location=lambda storage, loc: storage)\n","\treturn checkpoint\n","\n","def load_model(path):\n","\tmodel = Wav2Lip()\n","\tprint(\"Load checkpoint from: {}\".format(path))\n","\tcheckpoint = _load(path)\n","\ts = checkpoint[\"state_dict\"]\n","\tnew_s = {}\n","\tfor k, v in s.items():\n","\t\tnew_s[k.replace('module.', '')] = v\n","\tmodel.load_state_dict(new_s)\n","\n","\tmodel = model.to(device)\n","\treturn model.eval()\n","# MAIN FUNCTION\n","if not os.path.isfile(face):\n","  raise ValueError('--face argument must be a valid path to video/image file')\n","\n","elif face.split('.')[1] in ['jpg', 'png', 'jpeg']:\n","  full_frames = [cv2.imread(face)]\n","  fps = fps\n","\n","else:\n","  video_stream = cv2.VideoCapture(face)\n","  fps = video_stream.get(cv2.CAP_PROP_FPS)\n","\n","  print('Reading video frames...')\n","\n","  full_frames = []\n","  while 1:\n","    still_reading, frame = video_stream.read()\n","    if not still_reading:\n","      video_stream.release()\n","      break\n","    if resize_factor > 1:\n","      frame = cv2.resize(frame, (frame.shape[1]//resize_factor, frame.shape[0]//resize_factor))\n","\n","    if rotate:\n","      frame = cv2.rotate(frame, cv2.cv2.ROTATE_90_CLOCKWISE)\n","\n","    y1, y2, x1, x2 =crop\n","    if x2 == -1: x2 = frame.shape[1]\n","    if y2 == -1: y2 = frame.shape[0]\n","\n","    frame = frame[y1:y2, x1:x2]\n","\n","    full_frames.append(frame)\n","\n","print (\"Number of frames available for inference: \"+str(len(full_frames)))\n","\n","if not audiof.endswith('.wav'):\n","  print('Extracting raw audio...')\n","  command = 'ffmpeg -y -i {} -strict -2 {}'.format(audiof, 'temp/temp.wav')\n","\n","  subprocess.call(command, shell=True)\n","  audiof = 'temp/temp.wav'\n","\n","wav = audio.load_wav(audiof, 16000)\n","mel = audio.melspectrogram(wav)\n","print(mel.shape)\n","\n","if np.isnan(mel.reshape(-1)).sum() > 0:\n","  raise ValueError('Mel contains nan! Using a TTS voice? Add a small epsilon noise to the wav file and try again')\n","\n","mel_chunks = []\n","mel_idx_multiplier = 80./fps \n","i = 0\n","while 1:\n","  start_idx = int(i * mel_idx_multiplier)\n","  if start_idx + mel_step_size > len(mel[0]):\n","    mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n","    break\n","  mel_chunks.append(mel[:, start_idx : start_idx + mel_step_size])\n","  i += 1\n","\n","print(\"Length of mel chunks: {}\".format(len(mel_chunks)))\n","\n","full_frames = full_frames[:len(mel_chunks)]\n","\n","batch_size =wav2lip_batch_size\n","gen = datagen(full_frames.copy(), mel_chunks)\n","\n","for i, (img_batch, mel_batch, frames, coords) in enumerate(tqdm(gen, \n","                    total=int(np.ceil(float(len(mel_chunks))/batch_size)))):\n","  if i == 0:\n","    model = load_model(checkpoint_path)\n","    print (\"Model loaded\")\n","\n","    frame_h, frame_w = full_frames[0].shape[:-1]\n","    out = cv2.VideoWriter('temp/result.avi', \n","                cv2.VideoWriter_fourcc(*'DIVX'), fps, (frame_w, frame_h))\n","\n","  img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n","  mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n","\n","  with torch.no_grad():\n","    pred = model(mel_batch, img_batch)\n","\n","  pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n","  \n","  for p, f, c in zip(pred, frames, coords):\n","    y1, y2, x1, x2 = c\n","    p = cv2.resize(p.astype(np.uint8), (x2 - x1, y2 - y1))\n","\n","    f[y1:y2, x1:x2] = p\n","    out.write(f)\n","\n","out.release()\n","\n","command = 'ffmpeg -y -i {} -i {} -strict -2 -q:v 1 {}'.format(audiof, 'temp/result.avi', outfile)\n","subprocess.call(command, shell=platform.system() != 'Windows')\n","\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Using cuda for inference.\n","Reading video frames...\n","Number of frames available for inference: 862\n","Extracting raw audio...\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["(80, 9402)\n","Length of mel chunks: 1175\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n","  2%|▏         | 1/54 [00:05<04:29,  5.08s/it]\u001b[A\n","  4%|▎         | 2/54 [00:05<03:16,  3.78s/it]\u001b[A\n","  6%|▌         | 3/54 [00:06<02:25,  2.86s/it]\u001b[A\n","  7%|▋         | 4/54 [00:07<01:51,  2.22s/it]\u001b[A\n","  9%|▉         | 5/54 [00:08<01:27,  1.78s/it]\u001b[A\n"," 11%|█         | 6/54 [00:08<01:10,  1.46s/it]\u001b[A\n"," 13%|█▎        | 7/54 [00:09<00:58,  1.24s/it]\u001b[A\n"," 15%|█▍        | 8/54 [00:10<00:49,  1.09s/it]\u001b[A\n"," 17%|█▋        | 9/54 [00:10<00:44,  1.02it/s]\u001b[A\n"," 19%|█▊        | 10/54 [00:11<00:39,  1.11it/s]\u001b[A\n"," 20%|██        | 11/54 [00:12<00:35,  1.23it/s]\u001b[A\n"," 22%|██▏       | 12/54 [00:12<00:33,  1.27it/s]\u001b[A\n"," 24%|██▍       | 13/54 [00:13<00:31,  1.29it/s]\u001b[A\n"," 26%|██▌       | 14/54 [00:14<00:30,  1.31it/s]\u001b[A\n"," 28%|██▊       | 15/54 [00:15<00:29,  1.33it/s]\u001b[A\n"," 30%|██▉       | 16/54 [00:15<00:28,  1.35it/s]\u001b[A\n"," 31%|███▏      | 17/54 [00:16<00:26,  1.39it/s]\u001b[A\n"," 33%|███▎      | 18/54 [00:17<00:25,  1.43it/s]\u001b[A\n"," 35%|███▌      | 19/54 [00:17<00:23,  1.47it/s]\u001b[A\n"," 37%|███▋      | 20/54 [00:18<00:23,  1.47it/s]\u001b[A\n"," 39%|███▉      | 21/54 [00:19<00:22,  1.46it/s]\u001b[A\n"," 41%|████      | 22/54 [00:19<00:21,  1.46it/s]\u001b[A\n"," 43%|████▎     | 23/54 [00:20<00:21,  1.47it/s]\u001b[A\n"," 44%|████▍     | 24/54 [00:21<00:20,  1.46it/s]\u001b[A\n"," 46%|████▋     | 25/54 [00:21<00:20,  1.45it/s]\u001b[A\n"," 48%|████▊     | 26/54 [00:22<00:19,  1.42it/s]\u001b[A\n"," 50%|█████     | 27/54 [00:23<00:19,  1.41it/s]\u001b[A\n"," 52%|█████▏    | 28/54 [00:24<00:18,  1.41it/s]\u001b[A\n"," 54%|█████▎    | 29/54 [00:24<00:17,  1.42it/s]\u001b[A\n"," 56%|█████▌    | 30/54 [00:25<00:17,  1.41it/s]\u001b[A\n"," 57%|█████▋    | 31/54 [00:26<00:16,  1.41it/s]\u001b[A\n"," 59%|█████▉    | 32/54 [00:27<00:15,  1.40it/s]\u001b[A\n"," 61%|██████    | 33/54 [00:27<00:15,  1.37it/s]\u001b[A\n"," 63%|██████▎   | 34/54 [00:28<00:15,  1.33it/s]\u001b[A\n"," 65%|██████▍   | 35/54 [00:29<00:14,  1.34it/s]\u001b[A\n"," 67%|██████▋   | 36/54 [00:30<00:14,  1.20it/s]\u001b[A\n"," 69%|██████▊   | 37/54 [00:30<00:12,  1.32it/s]\u001b[A\n"," 70%|███████   | 38/54 [00:31<00:11,  1.43it/s]\u001b[A\n"," 72%|███████▏  | 39/54 [00:32<00:10,  1.50it/s]\u001b[A\n"," 74%|███████▍  | 40/54 [00:32<00:09,  1.47it/s]\u001b[A\n"," 76%|███████▌  | 41/54 [00:33<00:08,  1.45it/s]\u001b[A\n"," 78%|███████▊  | 42/54 [00:34<00:08,  1.44it/s]\u001b[A\n"," 80%|███████▉  | 43/54 [00:34<00:07,  1.43it/s]\u001b[A\n"," 81%|████████▏ | 44/54 [00:35<00:07,  1.42it/s]\u001b[A\n"," 83%|████████▎ | 45/54 [00:36<00:06,  1.41it/s]\u001b[A\n"," 85%|████████▌ | 46/54 [00:37<00:05,  1.42it/s]\u001b[A\n"," 87%|████████▋ | 47/54 [00:37<00:04,  1.42it/s]\u001b[A\n"," 89%|████████▉ | 48/54 [00:38<00:04,  1.41it/s]\u001b[A\n"," 91%|█████████ | 49/54 [00:39<00:03,  1.42it/s]\u001b[A\n"," 93%|█████████▎| 50/54 [00:39<00:02,  1.40it/s]\u001b[A\n"," 94%|█████████▍| 51/54 [00:40<00:02,  1.41it/s]\u001b[A\n"," 96%|█████████▋| 52/54 [00:41<00:01,  1.42it/s]\u001b[A\n"," 98%|█████████▊| 53/54 [00:41<00:00,  1.43it/s]\u001b[A\n","100%|██████████| 54/54 [00:46<00:00,  1.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Load checkpoint from: checkpoints/wav2lip_gan.pth\n","Model loaded\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [01:07<00:00,  6.74s/it]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"sfJhEC_QO3m6"},"source":["### Displaying the result"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261,"output_embedded_package_id":"11RYULNR5_4ScDIvy1rj70v27CPewFKjh"},"id":"gAxiz5A75rOb","executionInfo":{"status":"ok","timestamp":1621856851939,"user_tz":-330,"elapsed":6210,"user":{"displayName":"Rithish kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjME8_kNalfGY9iFc4xUaumwUwkx9zhau1IhKy2Fg=s64","userId":"09250092512725729505"}},"outputId":"ec1f8159-f913-4830-ce9c-f0285a0f070a"},"source":["from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}